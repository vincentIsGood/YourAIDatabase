# C LLM for GGML support (download either `ctransformers` OR `llama-cpp-python` OR both)
## Useful environment vars (for CUDA 11)
# set PYTHONUTF8=1  (useful on windows)
# set CT_CUBLAS=1   (build ctransformers with CUDA enabled)
# Ref: https://github.com/marella/ctransformers/blob/main/README.md#langchain
#ctransformers

## llama-cpp-python (with GPU, see https://python.langchain.com/docs/integrations/llms/llamacpp)
# llama-cpp-python

transformers
sentence_transformers
langchain == 0.0.239
langchain[llms]
unstructured[local-inference] >= 0.8.1
chromadb

requests
# https://stackoverflow.com/questions/76247540/loading-data-using-unstructuredurlloader-of-langchain-halts-with-tp-num-c-buf
python-magic
python-magic-bin
tabulate
pdf2image
pytesseract

# download torch on its offical website
